{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\DSS7884\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\DSS7884\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')], [('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# let's check some of the tagged data\n",
    "print(nltk_data[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation set in the ratio 80:20\n",
    "\n",
    "train_set,test_set = train_test_split(nltk_data,train_size=0.80,test_size=0.20,random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80126\n",
      "20550\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged = [tup for sent in train_set for tup in sent]\n",
    "tagged_test = [tup[0] for sent in test_set for tup in sent]\n",
    "print(len(train_tagged))\n",
    "print(len(tagged_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city', 'NOUN'), (\"'s\", 'PRT'), ('Campaign', 'NOUN'), ('Finance', 'NOUN')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking some of the tagged words.\n",
    "train_tagged[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'VERB', 'ADJ', 'NOUN', 'PRON', 'ADP', 'ADV', 'X', 'PRT', 'DET', 'CONJ', '.', 'NUM'}\n"
     ]
    }
   ],
   "source": [
    "# checking no of unique tags are present in training data\n",
    "tags = {tag for word,tag in train_tagged}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029\n"
     ]
    }
   ],
   "source": [
    "#checking the no of words are present in vocabulary\n",
    "vocab = {word for word,tag in train_tagged}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### computing  emission probabilties for a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute emission probability for a given word for a given tag\n",
    "def word_given_tag(word,tag,train_bag= train_tagged):\n",
    "    list_tag = [x for x in train_bag if x[1] == tag]\n",
    "    tag_count = len(list_tag)    \n",
    "    w_in_tag = [x[0] for x in list_tag if x[0]==word]    \n",
    "    word_count_given_tag = len(w_in_tag)    \n",
    "    return (word_count_given_tag,tag_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute transition probabilties for a given tag and previous tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute transition probabilities of a previous and next tag\n",
    "def t2_given_t1(t2,t1,train_bag=train_tagged):\n",
    "    tags = [x[1] for x in train_bag]\n",
    "    t1_tags = [x for x in tags if x==t1]\n",
    "    count_of_t1 = len(t1_tags)\n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
    "    count_t2_given_t1 = len(t2_given_t1)\n",
    "    return(count_t2_given_t1,count_of_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4430, 6906)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NOUN','DET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating transition matrix of tags where each column is t2 and each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "matrix_of_tags = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        matrix_of_tags[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the matrix to dataframe\n",
    "tags_df = pd.DataFrame(matrix_of_tags, columns = list(tags), index=list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>X</th>\n",
       "      <th>PRT</th>\n",
       "      <th>DET</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>.</th>\n",
       "      <th>NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.170015</td>\n",
       "      <td>0.065518</td>\n",
       "      <td>0.111869</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.084224</td>\n",
       "      <td>0.216089</td>\n",
       "      <td>0.030133</td>\n",
       "      <td>0.133616</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.034279</td>\n",
       "      <td>0.023037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.013186</td>\n",
       "      <td>0.067506</td>\n",
       "      <td>0.695336</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.076757</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.022043</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>0.066326</td>\n",
       "      <td>0.021649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.146882</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>0.262892</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>0.177146</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.013219</td>\n",
       "      <td>0.042091</td>\n",
       "      <td>0.241499</td>\n",
       "      <td>0.009131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.486524</td>\n",
       "      <td>0.073550</td>\n",
       "      <td>0.207401</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>0.030608</td>\n",
       "      <td>0.096848</td>\n",
       "      <td>0.012791</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.039287</td>\n",
       "      <td>0.007309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.107266</td>\n",
       "      <td>0.322306</td>\n",
       "      <td>0.070365</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.034101</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.323578</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.038555</td>\n",
       "      <td>0.063112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.339377</td>\n",
       "      <td>0.127316</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.122980</td>\n",
       "      <td>0.081198</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>0.013402</td>\n",
       "      <td>0.073315</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.135199</td>\n",
       "      <td>0.030351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.207951</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>0.065176</td>\n",
       "      <td>0.055428</td>\n",
       "      <td>0.141437</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.076261</td>\n",
       "      <td>0.186544</td>\n",
       "      <td>0.051414</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.084606</td>\n",
       "      <td>0.248335</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.021152</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.096357</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.043087</td>\n",
       "      <td>0.058363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.039096</td>\n",
       "      <td>0.202867</td>\n",
       "      <td>0.641471</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.045613</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.017666</td>\n",
       "      <td>0.021720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.163697</td>\n",
       "      <td>0.118040</td>\n",
       "      <td>0.345768</td>\n",
       "      <td>0.060134</td>\n",
       "      <td>0.051225</td>\n",
       "      <td>0.054566</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.119154</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.033964</td>\n",
       "      <td>0.038975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.089469</td>\n",
       "      <td>0.044628</td>\n",
       "      <td>0.224850</td>\n",
       "      <td>0.065604</td>\n",
       "      <td>0.092359</td>\n",
       "      <td>0.052761</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.170912</td>\n",
       "      <td>0.059075</td>\n",
       "      <td>0.093429</td>\n",
       "      <td>0.078232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.361641</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.202951</td>\n",
       "      <td>0.027348</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.117308</td>\n",
       "      <td>0.181720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VERB       ADJ      NOUN      PRON       ADP       ADV         X  \\\n",
       "VERB  0.170015  0.065518  0.111869  0.034924  0.090675  0.084224  0.216089   \n",
       "ADJ   0.013186  0.067506  0.695336  0.000590  0.076757  0.005511  0.022043   \n",
       "NOUN  0.146882  0.012175  0.262892  0.005044  0.177146  0.016828  0.029133   \n",
       "PRON  0.486524  0.073550  0.207401  0.008223  0.022385  0.030608  0.096848   \n",
       "ADP   0.007762  0.107266  0.322306  0.070365  0.017305  0.013233  0.034101   \n",
       "ADV   0.339377  0.127316  0.033898  0.016555  0.122980  0.081198  0.020102   \n",
       "X     0.207951  0.015291  0.065176  0.055428  0.141437  0.023700  0.076261   \n",
       "PRT   0.405405  0.084606  0.248335  0.014884  0.021152  0.010184  0.013709   \n",
       "DET   0.039096  0.202867  0.641471  0.003620  0.009412  0.012019  0.045613   \n",
       "CONJ  0.163697  0.118040  0.345768  0.060134  0.051225  0.054566  0.008352   \n",
       ".     0.089469  0.044628  0.224850  0.065604  0.092359  0.052761  0.026327   \n",
       "NUM   0.018712  0.033825  0.361641  0.001439  0.035984  0.002519  0.202951   \n",
       "\n",
       "           PRT       DET      CONJ         .       NUM  \n",
       "VERB  0.030133  0.133616  0.005621  0.034279  0.023037  \n",
       "ADJ   0.009841  0.004723  0.016532  0.066326  0.021649  \n",
       "NOUN  0.043960  0.013219  0.042091  0.241499  0.009131  \n",
       "PRON  0.012791  0.010050  0.005025  0.039287  0.007309  \n",
       "ADP   0.001654  0.323578  0.000763  0.038555  0.063112  \n",
       "ADV   0.013402  0.073315  0.006307  0.135199  0.030351  \n",
       "X     0.186544  0.051414  0.010130  0.163800  0.002867  \n",
       "PRT   0.001958  0.096357  0.001958  0.043087  0.058363  \n",
       "DET   0.000290  0.005792  0.000434  0.017666  0.021720  \n",
       "CONJ  0.005568  0.119154  0.000557  0.033964  0.038975  \n",
       ".     0.002247  0.170912  0.059075  0.093429  0.078232  \n",
       "NUM   0.027348  0.003598  0.012954  0.117308  0.181720  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi Algorithm\n",
    "\n",
    "1. Given a sequence of words,iterate through the sequence\n",
    "3. for each word (starting from first word in sequence) calculate the product of emission probabilties and transition probabilties for all possible tags.\n",
    "4. assign the tag which has maximum probability obtained.\n",
    "5. move to the next word in sequence and repeat steps 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Viterbi Algorithm\n",
    "def Viterbi(words, train_bag = train_tagged):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = [] #initialising list of probability column for a given observation\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                trans_prob = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                trans_prob = tags_df.loc[state[-1], tag]   \n",
    "            # compute emission and state probabilities\n",
    "            emiss_prob = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_prob = emiss_prob * trans_prob    \n",
    "            p.append(state_prob) \n",
    "        pmax = max(p) # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Vanilla Viterbi Algorithm on sampled test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "# choosing random 5 sentences\n",
    "x = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "# list of sents\n",
    "run_test = [test_set[i] for i in x]\n",
    "# list of tagged words\n",
    "run_test_base = [tup for sent in run_test for tup in sent]\n",
    "# list of untagged words\n",
    "tagged_test = [tup[0] for sent in run_test for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  14.892029047012329\n",
      "Vanilla Viterbi Algorithm Accuracy:  92.98245614035088\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tag_sequence = Viterbi(tagged_test)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "# checking the accuracy of algorithm\n",
    "check = [i for i, j in zip(tag_sequence, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tag_sequence)\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('theaters', 'VERB'), ('theaters', 'NOUN')),\n",
       " (('hospitals', 'VERB'), ('hospitals', 'NOUN')),\n",
       " (('about', 'ADP'), ('about', 'ADV')),\n",
       " (('77,000', 'VERB'), ('77,000', 'NUM')),\n",
       " (('free', 'ADJ'), ('free', 'ADV')),\n",
       " (('ancient', 'VERB'), ('ancient', 'ADJ')),\n",
       " (('New', 'NOUN'), ('New', 'ADJ')),\n",
       " (('361.8', 'VERB'), ('361.8', 'NUM'))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tag_sequence, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can see that all of unknown words have been tagged as 'NUM' as 'NUM' is the first tag in tag list and is assigned\n",
    "if unknown word is encountered (emission probability =0).\n",
    "\n",
    "### Viterbi Modification-Techniques (1st technique)\n",
    "\n",
    "* assign based on transition probabilities only in case of unknown words as emission probability for unknown word is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use transition probability of tags when emission probability is zero (in case of unknown words)\n",
    "\n",
    "def Viterbi_1(words, train_bag = train_tagged):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = []   #list of probability column for a given observation\n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                prob_trans = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                prob_trans = tags_df.loc[state[-1], tag]\n",
    "            # computing emission and state probabilities\n",
    "            prob_emiss = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            prob_state = prob_emiss * prob_trans    \n",
    "            p.append(prob_state)\n",
    "            p_transition.append(prob_trans)          \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)]   \n",
    "        if(pmax==0):    # if probability is zero (unknown word) then use transition probability\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  13.930127143859863\n",
      "Modified Viterbi_1 Accuracy:  94.73684210526315\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time() # code to start the timer for execution\n",
    "tag_sequence = Viterbi_1(tagged_test)\n",
    "end = time.time() # code to end timer for the execution\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "check = [i for i, j in zip(tag_sequence, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tag_sequence)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "applying weights based on the probability of tag occurance to the transition probabilities of tags and then use the resulting probability for predicting unknown words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VERB', 0.13543668721763222),\n",
       " ('ADJ', 0.06341262511544318),\n",
       " ('NOUN', 0.2870229388712777),\n",
       " ('PRON', 0.027319471831864815),\n",
       " ('ADP', 0.09808301924468961),\n",
       " ('ADV', 0.03166263135561491),\n",
       " ('X', 0.06529715697776003),\n",
       " ('PRT', 0.03186231685095974),\n",
       " ('DET', 0.08618925192821307),\n",
       " ('CONJ', 0.02241469685245738),\n",
       " ('.', 0.11661632928138183),\n",
       " ('NUM', 0.03468287447270549)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_of_tag = [] # creating a list containing tuples of POS tags and POS tag occurance probability\n",
    "total_tag = len([tag for word,tag in train_tagged])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged if tag==t]\n",
    "    probability_of_tag.append((t,len(each_tag)/total_tag))\n",
    "probability_of_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_1(words, train_bag = train_tagged):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = []     #initialising list of probability column for a given observation\n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                prob_trans = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                prob_trans = tags_df.loc[state[-1], tag]    \n",
    "            # computing the emission and state probabilities\n",
    "            prob_emiss = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            prob_state = prob_emiss * prob_trans    \n",
    "            p.append(prob_state)\n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in probability_of_tag if pair[0]==tag ]\n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            prob_trans = tag_p[0]*prob_trans             \n",
    "            p_transition.append(prob_trans)\n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        # if probability is zero (unknown word) then use weighted transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                                       \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)]  \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  14.055493116378784\n",
      "Modified Viterbi_1 Accuracy:  94.73684210526315\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tag_sequence = Viterbi_1(tagged_test)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "check = [i for i, j in zip(tag_sequence, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tag_sequence)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compared to previous viterbi alogorithm, we observe that better accuracy is obtained by using weighted transition probabilties.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('about', 'ADP'), ('about', 'ADV')),\n",
       " (('77,000', 'NOUN'), ('77,000', 'NUM')),\n",
       " (('free', 'ADJ'), ('free', 'ADV')),\n",
       " (('ancient', 'NOUN'), ('ancient', 'ADJ')),\n",
       " (('New', 'NOUN'), ('New', 'ADJ')),\n",
       " (('361.8', 'NOUN'), ('361.8', 'NUM'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tag_sequence, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been **correctly POS tagged by Viterbi_1** as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "* about:correctly tagged as ADV\n",
    "* 77,000:correctly tagged as NUM\n",
    "* free: correctly tagged as ADV\n",
    "* 361.8: correctly tagged as NUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Modification-Technique II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative solution for unknown words:** \n",
    "\n",
    "*we further observe that POS tag 'X' can be easily encapsulated in regex rule, so we extract it only based on ruled based tagger.*\n",
    "\n",
    "Let's define a rule based tagger as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                   # nouns\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "]\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backing off to rule based tagger in case unknown word is encountered.\n",
    "def Viterbi_2(words, train_bag = train_tagged):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = []      #initialise list of probability column for a given observation\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                prob_trans = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                prob_trans = tags_df.loc[state[-1], tag]  \n",
    "            # computing emission and state probabilities\n",
    "            prob_emiss = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            prob_state = prob_emiss * prob_trans    \n",
    "            p.append(prob_state)    \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)]                \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  14.0182785987854\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tag_sequence = Viterbi_2(tagged_test)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi_2 Accuracy:  95.6140350877193\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tag_sequence, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tag_sequence)\n",
    "print('Modified Viterbi_2 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('bans', 'NOUN'), ('bans', 'VERB')),\n",
       " (('about', 'ADP'), ('about', 'ADV')),\n",
       " (('free', 'ADJ'), ('free', 'ADV')),\n",
       " (('ancient', 'NOUN'), ('ancient', 'ADJ')),\n",
       " (('New', 'NOUN'), ('New', 'ADJ'))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tag_sequence, test_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by Viterbi_2 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "* bans:correctly tagged as verb\n",
    "* about:correctly tagged as ADV\n",
    "* free: correctly tagged as ADV\n",
    "* New: correctly tagged as ADJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As We know that the rule based tagger assigns 'NOUN' by default if word does not fall in any rule, to correct this let's assign the tags for any such word based purely on transition probability of tags. for this to happen,first we will modify the rule based tagger to output 'NN' instead of 'NOUN' in case word does not satisfy any rules. We also observe that any capitalized word can still be defaulted as 'NOUN' so will add one more rule for that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'^[A-Z][a-z].*', 'NOUN'),       # NOUN\n",
    "    (r'.*', 'NN')                     # default\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "]\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified version of Viterbi algorithm\n",
    "def Viterbi_2(words, train_bag = train_tagged):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = []    #initialise list of probability column for a given observation\n",
    "        p_transition =[] # for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                prob_trans = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                prob_trans = tags_df.loc[state[-1], tag]\n",
    "            # compute emission and state probabilities\n",
    "            prob_emiss = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            prob_state = prob_emiss * prob_trans    \n",
    "            p.append(prob_state) \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in probability_of_tag if pair[0]==tag ]\n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            prob_trans = tag_p[0]*prob_trans\n",
    "            p_transition.append(prob_trans)\n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1] \n",
    "        # obtaining the state for which probability is maximum\n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "            # if unknown word does not satisfy any rule, find the tag with maximum transition probability\n",
    "            if state_max == 'NN':\n",
    "                pmax = max(p_transition)\n",
    "                state_max = T[p_transition.index(pmax)]                      \n",
    "        else:\n",
    "             if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  14.236104249954224\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tag_sequence = Viterbi_2(tagged_test)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi Algorithm Accuracy:  95.6140350877193\n"
     ]
    }
   ],
   "source": [
    "# checking the accuracy\n",
    "check = [i for i, j in zip(tag_sequence, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tag_sequence)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('bans', 'NOUN'), ('bans', 'VERB')),\n",
       " (('about', 'ADP'), ('about', 'ADV')),\n",
       " (('free', 'ADJ'), ('free', 'ADV')),\n",
       " (('ancient', 'NOUN'), ('ancient', 'ADJ')),\n",
       " (('New', 'NOUN'), ('New', 'ADJ'))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tag_sequence, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following list of words has been correctly tagged by Viterbi_2 as compared to Viterbi_1\n",
    "* bans:correctly tagged as verb\n",
    "* about:correctly tagged as ADV\n",
    "* free: correctly tagged as ADV\n",
    "* New: correctly tagged as ADJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate vanilla Viterbi and modified Viterbi on entire test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_test = [tup[0] for sent in test_set for tup in sent]\n",
    "test_run_base = [tup for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  2447.593504190445\n",
      "Modified Viterbi Algorithm Accuracy:  91.31386861313868\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences for Viterbi (rule-based)\n",
    "start = time.time()\n",
    "tag_sequence = Viterbi(tagged_test)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tag_sequence, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tag_sequence)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  2744.008337020874\n",
      "Modified Viterbi Algorithm Accuracy:  95.0316301703163\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences (after modification)\n",
    "start = time.time()\n",
    "tag_sequence = Viterbi_2(tagged_test)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tag_sequence, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tag_sequence)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging on sample 'Test_sentences.txt' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Test_sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f.read()\n",
    "sample_test_sent = text.splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of untagged words\n",
    "sample_tokens = [word for sent in sample_test_sent for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mobile',\n",
       " 'operating',\n",
       " 'system',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'Google.',\n",
       " 'Android',\n",
       " 'has',\n",
       " 'been',\n",
       " 'the',\n",
       " 'best-selling',\n",
       " 'OS',\n",
       " 'worldwide',\n",
       " 'on',\n",
       " 'smartphones',\n",
       " 'since',\n",
       " '2011',\n",
       " 'and',\n",
       " 'on',\n",
       " 'tablets',\n",
       " 'since',\n",
       " '2013.',\n",
       " 'Google',\n",
       " 'and',\n",
       " 'Twitter',\n",
       " 'made',\n",
       " 'a',\n",
       " 'deal',\n",
       " 'in',\n",
       " '2015',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'Google',\n",
       " 'access',\n",
       " 'to',\n",
       " \"Twitter's\",\n",
       " 'firehose.',\n",
       " 'Twitter',\n",
       " 'is',\n",
       " 'an',\n",
       " 'online',\n",
       " 'news',\n",
       " 'and',\n",
       " 'social',\n",
       " 'networking',\n",
       " 'service',\n",
       " 'on',\n",
       " 'which',\n",
       " 'users',\n",
       " 'post',\n",
       " 'and',\n",
       " 'interact',\n",
       " 'with',\n",
       " 'messages',\n",
       " 'known',\n",
       " 'as',\n",
       " 'tweets.',\n",
       " 'Before',\n",
       " 'entering',\n",
       " 'politics,',\n",
       " 'Donald',\n",
       " 'Trump',\n",
       " 'was',\n",
       " 'a',\n",
       " 'domineering',\n",
       " 'businessman',\n",
       " 'and',\n",
       " 'a',\n",
       " 'television',\n",
       " 'personality.',\n",
       " 'The',\n",
       " '2018',\n",
       " 'FIFA',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'is',\n",
       " 'the',\n",
       " '21st',\n",
       " 'FIFA',\n",
       " 'World',\n",
       " 'Cup,',\n",
       " 'an',\n",
       " 'international',\n",
       " 'football',\n",
       " 'tournament',\n",
       " 'contested',\n",
       " 'once',\n",
       " 'every',\n",
       " 'four',\n",
       " 'years.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'to',\n",
       " 'be',\n",
       " 'held',\n",
       " 'in',\n",
       " 'Eastern',\n",
       " 'Europe',\n",
       " 'and',\n",
       " 'the',\n",
       " '11th',\n",
       " 'time',\n",
       " 'that',\n",
       " 'it',\n",
       " 'has',\n",
       " 'been',\n",
       " 'held',\n",
       " 'in',\n",
       " 'Europe.',\n",
       " 'Show',\n",
       " 'me',\n",
       " 'the',\n",
       " 'cheapest',\n",
       " 'round',\n",
       " 'trips',\n",
       " 'from',\n",
       " 'Dallas',\n",
       " 'to',\n",
       " 'Atlanta',\n",
       " 'I',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'see',\n",
       " 'flights',\n",
       " 'from',\n",
       " 'Denver',\n",
       " 'to',\n",
       " 'Philadelphia.',\n",
       " 'Show',\n",
       " 'me',\n",
       " 'the',\n",
       " 'price',\n",
       " 'of',\n",
       " 'the',\n",
       " 'flights',\n",
       " 'leaving',\n",
       " 'Atlanta',\n",
       " 'at',\n",
       " 'about',\n",
       " '3',\n",
       " 'in',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'and',\n",
       " 'arriving',\n",
       " 'in',\n",
       " 'San',\n",
       " 'Francisco.',\n",
       " 'NASA',\n",
       " 'invited',\n",
       " 'social',\n",
       " 'media',\n",
       " 'users',\n",
       " 'to',\n",
       " 'experience',\n",
       " 'the',\n",
       " 'launch',\n",
       " 'of',\n",
       " 'ICESAT-2',\n",
       " 'Satellite.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  24.36722493171692\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tag_sequence = Viterbi(sample_tokens)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'VERB'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'VERB'),\n",
       " ('Android', 'VERB'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'VERB'),\n",
       " ('worldwide', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'VERB'),\n",
       " ('Google', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'VERB'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'VERB'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'VERB'),\n",
       " ('firehose.', 'VERB'),\n",
       " ('Twitter', 'VERB'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'VERB'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'VERB'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'VERB'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'VERB'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'VERB'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'VERB'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'VERB'),\n",
       " ('FIFA', 'VERB'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'VERB'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'VERB'),\n",
       " ('FIFA', 'VERB'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'VERB'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'VERB'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'VERB'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'VERB'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'VERB'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'VERB'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'VERB'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'VERB'),\n",
       " ('NASA', 'VERB'),\n",
       " ('invited', 'VERB'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'VERB'),\n",
       " ('Satellite.', 'VERB')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tag_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that several words have been misclassified by vanilla Viterbi POS tagger, for example:\n",
    "* Android as VERB\n",
    "* has as verb\n",
    "* 2015 as verb\n",
    "* 2011 as verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  22.67865014076233\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tag_sequence = Viterbi_2(sample_tokens)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NOUN'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'VERB'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'NOUN'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'NOUN'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NOUN'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NOUN'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'NOUN'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'NOUN'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'NOUN'),\n",
       " ('NASA', 'NOUN'),\n",
       " ('invited', 'VERB'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'NOUN'),\n",
       " ('Satellite.', 'NOUN')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tag_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these cases were correctly POS tagged by Viterbi_2:\n",
    "* Android as NOUN\n",
    "* 2011 as NUM\n",
    "* 2018 as NUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla Viterbi Algorithm Accuracy:  **92.98245614035088**\n",
    "\n",
    "Modified Viterbi Algorithm Accuracy:  **95.0316301703163**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* about:correctly tagged as ADV\n",
    "* free: correctly tagged as ADV\n",
    "* New: correctly tagged as ADJ\n",
    "* Android: correctly tagged as NOUN\n",
    "* Google: correctly tagged as NOUN\n",
    "* 2011 : correctly tagged as NUM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
